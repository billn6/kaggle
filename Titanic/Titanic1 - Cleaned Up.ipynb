{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Titanic Classification Exercise - First Effort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation\n",
    "\n",
    "This is a practical exercise based on what I learned from the <a href=\"https://www.udemy.com/complete-guide-to-tensorflow-for-deep-learning-with-python/\">Complete Guide to TensorFlow for Deep Learning in Python</a> course on Udemy.\n",
    "\n",
    "It is also the culmination of my 10% Personal Goal at work for 2019.  My goal was to complete the course and then apply what I learned to a machine learning problem, preferrably before 7/17/19 in order to get my \"5\" rating.\n",
    "\n",
    "This file is complete and was submitted to the Titanic contest on 5/24/19.  It resulted in a 0.65550 Public Score.\n",
    "\n",
    "I'm OK with the result as a first effort using TensorFlow.  I have a lot to learn, particularly about feature engineering for TensorFlow.  My top score is 0.75660 based on a Scikit-learn LinearDiscriminantAnalysis model and better feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Not use this file again.\n",
    "\n",
    "Lesson learned - once I have submitted an entry to Kaggle, don't change the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This works with the *tfdeeplearning* conda environment on my laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO (in a copy of this file)\n",
    "\n",
    "<ol>\n",
    "<li><b><i>Done 5/24/19 </i></b>make a copy and clean it up; store on Github\n",
    "<li>how to do cross_validation in TF?\n",
    "<li>work with categorical data: Pclass and Sex\n",
    "<li>try scikit-learn models instead\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with some Titanic Training Data, we'll be trying to use various features of an individual to predict whether they **survive** the sinking.\n",
    "\n",
    "Data is from https://www.kaggle.com/c/titanic/data\n",
    "\n",
    "Here is some information about the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Column Name</th>\n",
    "<th>Type</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>PassengerId</td>\n",
    "<td>Continuous</td>\n",
    "<td>ID of the passenger.  Artificial, **not used in the model.**</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Survived</td>\n",
    "<td>Categorical</td>\n",
    "<td>**The label.**</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Pclass</td>\n",
    "<td>Categorical</td>\n",
    "<td>The ticket class.  1=1st, 2=2nd, 3=3rd.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Name</td>\n",
    "<td>Categorical</td>\n",
    "<td>Passenger name.  **not used in the model**</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Sex</td>\n",
    "<td>Categorical</td>\n",
    "<td>Sex</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Age</td>\n",
    "<td>Continuous</td>\n",
    "<td>Age in years.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>SibSp</td>\n",
    "<td>Categorical</td>\n",
    "<td># of siblings / spouses aboard the Titanic  (could be continuous?)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>ParCh</td>\n",
    "<td>Categorical</td>\n",
    "<td># of parents / children aboard the Titanic  (could be continuous?)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Ticket</td>\n",
    "<td>Categorical</td>\n",
    "<td>ticket number.  **not used in model**</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Fare</td>\n",
    "<td>Continuous</td>\n",
    "<td>The price of the ticket.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Cabin</td>\n",
    "<td>Categorical</td>\n",
    "<td>cabin number</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Embarked</td>\n",
    "<td>Categorical</td>\n",
    "<td>Port of embarcation: C = Cherbourg, Q = Queenstown, S = Southampton</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in the titanic_train.csv data with pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_only = titanic.drop('PassengerId', axis=1) \\\n",
    "                      .drop('Name', axis=1) \\\n",
    "                      .drop('Ticket', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass   -0.338481\n",
       "Age      -0.077221\n",
       "SibSp    -0.035322\n",
       "Parch     0.081629\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_only[['Pclass', 'Age', 'SibSp', 'Parch']].corrwith(titanic_only['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detect NaN values: Age, Cabin, Embarked\n",
    "titanic_only.Age.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix NaN values\n",
    "values = {'Age': 35, 'Cabin': 'unk', 'Embarked': 'S'}\n",
    "titanic_only = titanic_only.fillna(value=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spot check NaN values to verify fix: Age, Cabin, Embarked\n",
    "titanic_only.Age.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Train Test Split on the Data\n",
    "\n",
    "This is left here for reference.  Kaggle provides test data so there is no need to split the training file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = titanic_only.drop('Survived',axis=1)\n",
    "y = titanic_only['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Feature Columns for tf.esitmator\n",
    "\n",
    "** Take note of categorical vs continuous values! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin',\n",
       "       'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_only.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import Tensorflow **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Create the tf.feature_columns for the categorical values. Use vocabulary lists or just use hash buckets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# categorical feature columns: 'Pclass', 'Sex', 'SibSp', 'Parch', \n",
    "#'Cabin', 'Embarked'\n",
    "#pclass = tf.feature_column.categorical_column_with_vocabulary_list('Pclass', ['1','2','3'])\n",
    "sex = tf.feature_column.categorical_column_with_vocabulary_list('Sex', ['male','female'])\n",
    "sibSp = tf.feature_column.categorical_column_with_hash_bucket('SibSp', hash_bucket_size=10)\n",
    "cabin = tf.feature_column.categorical_column_with_hash_bucket('Cabin', hash_bucket_size=10)\n",
    "embarked = tf.feature_column.categorical_column_with_vocabulary_list('Embarked', ['S', 'C', 'Q'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Embedding Columns ref https://www.tensorflow.org/guide/feature_columns#indicator_and_embedding_columns\n",
    "\n",
    "Given\n",
    "categorical_column = ... # Create any categorical column\n",
    "\n",
    "Represent the categorical column as an embedding column.\n",
    "This means creating an embedding vector lookup table with one element for each category.\n",
    "\n",
    "embedding_column = tf.feature_column.embedding_column(\n",
    "    categorical_column=categorical_column,\n",
    "    dimension=embedding_dimensions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sex_ec = tf.feature_column.embedding_column(categorical_column=sex,dimension=1)\n",
    "#sibSp_ec = tf.feature_column.embedding_column(categorical_column=sibSp,dimension=1)\n",
    "#cabin_ec = tf.feature_column.embedding_column(categorical_column=cabin,dimension=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the continuous feature_columns for the continuous values using numeric_column **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# continuous feature columns: age\n",
    "pclass = tf.feature_column.numeric_column('Pclass')\n",
    "age = tf.feature_column.numeric_column('Age')\n",
    "fare = tf.feature_column.numeric_column('Fare')\n",
    "parch = tf.feature_column.numeric_column('Parch')\n",
    "sibSpN = tf.feature_column.numeric_column('SibSp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Put all these variables into a single list with the variable name feat_cols **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feat_cols = [pclass, sex, sibSp, parch, cabin, embarked, age, fare]\n",
    "#feat_cols = [pclass, parch, age, fare, sex_ec, sibSpN]\n",
    "# this is the one that works - only numeric feature columns at this point\n",
    "feat_cols = [pclass, parch, age, fare, sibSpN]\n",
    "#feat_cols = [pclass, parch, age, fare]\n",
    "#feat_cols = [fare]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Input Function\n",
    "\n",
    "** Batch_size (auth used 30) is up to you. But do make sure to shuffle!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>unk</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>unk</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>unk</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
       "0       3    male  22.0      1      0   7.2500   unk        S\n",
       "1       1  female  38.0      1      0  71.2833   C85        C\n",
       "2       3  female  26.0      0      0   7.9250   unk        S\n",
       "3       1  female  35.0      1      0  53.1000  C123        S\n",
       "4       3    male  35.0      0      0   8.0500   unk        S"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X,y=y,batch_size=30,num_epochs=1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your model with tf.estimator\n",
    "\n",
    "**Create a LinearClassifier.(If you want to use a DNNClassifier, keep in mind you'll need to create embedded columns out of the cateogrical feature that use strings, check out the previous lecture on this for more info.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/1g/92h4zhdx7bd2999w69pr2b9h0000gn/T/tmpol10it7o\n",
      "INFO:tensorflow:Using config: {'_master': '', '_service': None, '_tf_random_seed': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11083f128>, '_device_fn': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_eval_distribute': None, '_global_id_in_cluster': 0, '_is_chief': True, '_protocol': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_task_id': 0, '_keep_checkpoint_every_n_hours': 10000, '_train_distribute': None, '_evaluation_master': '', '_task_type': 'worker', '_keep_checkpoint_max': 5, '_num_worker_replicas': 1, '_save_checkpoints_secs': 600, '_model_dir': '/var/folders/1g/92h4zhdx7bd2999w69pr2b9h0000gn/T/tmpol10it7o', '_num_ps_replicas': 0}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNClassifier(hidden_units=[5, 4],feature_columns=feat_cols,n_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train your model on the data, for at least 5000 steps. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/billneedels/anaconda/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2997: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /Users/billneedels/anaconda/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow/python/ops/lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/billneedels/anaconda/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/1g/92h4zhdx7bd2999w69pr2b9h0000gn/T/tmpol10it7o/model.ckpt.\n",
      "INFO:tensorflow:loss = 63.838085, step = 1\n",
      "INFO:tensorflow:global_step/sec: 160.138\n",
      "INFO:tensorflow:loss = 18.7236, step = 101 (0.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.013\n",
      "INFO:tensorflow:loss = 19.290203, step = 201 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.259\n",
      "INFO:tensorflow:loss = 21.02531, step = 301 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.999\n",
      "INFO:tensorflow:loss = 21.047491, step = 401 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.706\n",
      "INFO:tensorflow:loss = 17.523876, step = 501 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.342\n",
      "INFO:tensorflow:loss = 19.365917, step = 601 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.344\n",
      "INFO:tensorflow:loss = 19.732054, step = 701 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.751\n",
      "INFO:tensorflow:loss = 19.20573, step = 801 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.154\n",
      "INFO:tensorflow:loss = 18.716784, step = 901 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.737\n",
      "INFO:tensorflow:loss = 16.446095, step = 1001 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.909\n",
      "INFO:tensorflow:loss = 14.992404, step = 1101 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.486\n",
      "INFO:tensorflow:loss = 17.122665, step = 1201 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.683\n",
      "INFO:tensorflow:loss = 11.880358, step = 1301 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.513\n",
      "INFO:tensorflow:loss = 11.014345, step = 1401 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.691\n",
      "INFO:tensorflow:loss = 17.152035, step = 1501 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.672\n",
      "INFO:tensorflow:loss = 16.612194, step = 1601 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.07\n",
      "INFO:tensorflow:loss = 19.512407, step = 1701 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.457\n",
      "INFO:tensorflow:loss = 19.455547, step = 1801 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.246\n",
      "INFO:tensorflow:loss = 12.290086, step = 1901 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.418\n",
      "INFO:tensorflow:loss = 10.5234165, step = 2001 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.879\n",
      "INFO:tensorflow:loss = 13.707096, step = 2101 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.451\n",
      "INFO:tensorflow:loss = 17.025667, step = 2201 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.438\n",
      "INFO:tensorflow:loss = 7.302981, step = 2301 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.442\n",
      "INFO:tensorflow:loss = 16.843246, step = 2401 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.568\n",
      "INFO:tensorflow:loss = 10.747975, step = 2501 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.784\n",
      "INFO:tensorflow:loss = 14.294205, step = 2601 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.696\n",
      "INFO:tensorflow:loss = 15.908859, step = 2701 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.456\n",
      "INFO:tensorflow:loss = 16.625051, step = 2801 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.578\n",
      "INFO:tensorflow:loss = 12.5441885, step = 2901 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.629\n",
      "INFO:tensorflow:loss = 22.809895, step = 3001 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.17\n",
      "INFO:tensorflow:loss = 14.708525, step = 3101 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.185\n",
      "INFO:tensorflow:loss = 15.01812, step = 3201 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.771\n",
      "INFO:tensorflow:loss = 14.028649, step = 3301 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.103\n",
      "INFO:tensorflow:loss = 12.434267, step = 3401 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.63\n",
      "INFO:tensorflow:loss = 15.724741, step = 3501 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.559\n",
      "INFO:tensorflow:loss = 8.427396, step = 3601 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.938\n",
      "INFO:tensorflow:loss = 16.520817, step = 3701 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.746\n",
      "INFO:tensorflow:loss = 15.049021, step = 3801 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.261\n",
      "INFO:tensorflow:loss = 13.6972885, step = 3901 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.322\n",
      "INFO:tensorflow:loss = 12.25775, step = 4001 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.362\n",
      "INFO:tensorflow:loss = 15.452473, step = 4101 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.298\n",
      "INFO:tensorflow:loss = 16.637129, step = 4201 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.787\n",
      "INFO:tensorflow:loss = 12.735337, step = 4301 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.562\n",
      "INFO:tensorflow:loss = 11.206295, step = 4401 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.986\n",
      "INFO:tensorflow:loss = 13.839602, step = 4501 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.736\n",
      "INFO:tensorflow:loss = 12.554588, step = 4601 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.92\n",
      "INFO:tensorflow:loss = 11.622946, step = 4701 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.43\n",
      "INFO:tensorflow:loss = 17.523882, step = 4801 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.453\n",
      "INFO:tensorflow:loss = 16.222128, step = 4901 (0.377 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/1g/92h4zhdx7bd2999w69pr2b9h0000gn/T/tmpol10it7o/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 12.522065.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x13845b048>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data from Kaggle.  use this instead of the train_test_split portion of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
       "0       3    male  34.5      0      0   7.8292   NaN        Q\n",
       "1       3  female  47.0      1      0   7.0000   NaN        S\n",
       "2       2    male  62.0      0      0   9.6875   NaN        Q\n",
       "3       3    male  27.0      0      0   8.6625   NaN        S\n",
       "4       3  female  22.0      1      1  12.2875   NaN        S"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv('data/test.csv') \\\n",
    "                      .drop('Name', axis=1) \\\n",
    "                      .drop('Ticket', axis=1) \\\n",
    "                      .drop('PassengerId', axis=1) \n",
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix nulls\n",
    "\n",
    "Fill missing data values with medians.  Assuming the upper class passengers skew the means of both Fare and Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = {'Age': 27, 'Fare': 14.45} #'Cabin': 'unk', 'Embarked': 'S'}\n",
    "X_test = titanic_only.fillna(value=values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "** Create a prediction input function. Remember to only supply X_test data and keep shuffle=False. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_fn = tf.estimator.inputs.pandas_input_fn(x=X_test,batch_size=len(X_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use model.predict() and pass in your input function. This will produce a generator of predictions, which you can then transform into a list, with list() **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/1g/92h4zhdx7bd2999w69pr2b9h0000gn/T/tmpol10it7o/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = list(model.predict(input_fn=pred_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Each item in your list will look like this: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([0]),\n",
       " 'classes': array([b'0'], dtype=object),\n",
       " 'logistic': array([0.15570652], dtype=float32),\n",
       " 'logits': array([-1.6905273], dtype=float32),\n",
       " 'probabilities': array([0.8442935 , 0.15570651], dtype=float32)}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a list of only the class_ids key values from the prediction list of dictionaries, these are the predictions you will use to compare against the real y_test values. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1, 0, 0, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import classification_report from sklearn.metrics (*BillN: google if needed or LU in solution*) and then see if you can figure out how to use it to easily get a full report of your model's performance on the test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and Recall definitions: https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this step works if we have a y_test from a train test split.  \n",
    "# since we don't have that, we don't run this\n",
    "\n",
    "# print(classification_report(y_test,final_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model\n",
    "\n",
    "see http://shzhangji.com/blog/2018/05/14/serve-tensorflow-estimator-with-savedmodel/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='Pclass', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='Parch', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='Fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='Sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=1, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x13659f198>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " NumericColumn(key='SibSp', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/billneedels/anaconda/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py:800: EmbeddingColumn._parse_example_spec (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /Users/billneedels/anaconda/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2973: VocabularyListCategoricalColumn._parse_example_spec (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    }
   ],
   "source": [
    "feature_spec = tf.feature_column.make_parse_example_spec(feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['serving_default', 'classification']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: ['regression']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/1g/92h4zhdx7bd2999w69pr2b9h0000gn/T/tmpol10it7o/model.ckpt-5000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: export/temp-b'1558728262'/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'export/1558728262'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build receiver function, and export.\n",
    "serving_input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n",
    "export_dir = model.export_savedmodel('export', serving_input_receiver_fn)\n",
    "\n",
    "export_dir\n",
    "#model.export_saved_model(export_dir_base=\".\", serving_input_receiver_fn=input_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the saved model and use it for prediction\n",
    "\n",
    "Inspect the saved model from the command line using\n",
    "\n",
    "saved_model_cli show --dir export/1553868795 --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from export/1558728262/variables/variables\n"
     ]
    }
   ],
   "source": [
    "predict_fn = tf.contrib.predictor.from_saved_model(export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age        int64\n",
       "Fare       int64\n",
       "Parch      int64\n",
       "Pclass     int64\n",
       "Sex       object\n",
       "SibSp      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test inputs represented by Pandas DataFrame.\n",
    "\n",
    "# Not used.\n",
    "\n",
    "# This is shown here as an alternate technique.\n",
    "\n",
    "inputs = pd.DataFrame({\n",
    "    'Pclass': 3,\n",
    "    'Parch': 4,\n",
    "    'Age': 20,\n",
    "    'Fare': 100,\n",
    "    'SibSp': 3,}, \n",
    "    index=[0]\n",
    ")\n",
    "inputs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>SibSp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Row1</th>\n",
       "      <td>123</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row2</th>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Pclass  Parch  Age  Fare  SibSp\n",
       "Row1          123       3      4   60    30      3\n",
       "Row2          124       1      2   20   300      0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\n",
    "TAB = np.array([[''      ,'PassengerId','Pclass','Parch','Age','Fare','SibSp'],\n",
    "                 ['Row1' ,   123       ,   3    ,   4   ,  60 ,  30  ,   3   ],     # notional deceased\n",
    "                 ['Row2' ,   124       ,   1    ,   2   ,  20 , 300  ,   0   ]])   # notional survived\n",
    "\n",
    "data = TAB[1:,1:]\n",
    "index = TAB[1:,0]\n",
    "columns = TAB[0,1:]\n",
    "\n",
    "inputs = pd.DataFrame(\n",
    "    data=data,\n",
    "    index=index,\n",
    "    columns=columns,\n",
    "    dtype='int64'\n",
    ")\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert input data into serialized Example strings.\n",
    "examples = []\n",
    "for index, row in inputs.iterrows():\n",
    "    feature = {}\n",
    "    for col, value in row.iteritems():\n",
    "        feature[col] = tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature=feature\n",
    "        )\n",
    "    )\n",
    "    examples.append(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': array([[b'0', b'1'],\n",
       "        [b'0', b'1']], dtype=object),\n",
       " 'scores': array([[0.8442935 , 0.15570651],\n",
       "        [0.22101201, 0.778988  ]], dtype=float32)}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = predict_fn({'inputs': examples})\n",
    "predictions  # looks like a survivor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get this down to a single classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = [int(x[1].round(0)) for x in predictions['scores']]\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put this back together with the PassengerIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          123         0\n",
       "1          124         1"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengerids = inputs['PassengerId'].values\n",
    "passengerids\n",
    "mysub = pd.DataFrame({'PassengerId': passengerids, 'Survived': y_preds})\n",
    "mysub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Kaggle: Load the Test Data, Predict, and Assemble the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Pclass           int64\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Fare           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv('data/test.csv')\n",
    "X_test.head()\n",
    "#inputs = X_test.drop('PassengerId', axis=1) \\\n",
    "inputs = X_test.drop('Name', axis=1) \\\n",
    "                      .drop('Ticket', axis=1) \\\n",
    "                      .drop('Cabin', axis=1) \\\n",
    "                      .drop('Sex', axis=1) \\\n",
    "                      .drop('Embarked', axis=1)\n",
    "\n",
    "values = {'Age': 27, 'Fare': 14.45} #'Cabin': 'unk', 'Embarked': 'S'}\n",
    "X_test = inputs.fillna(value=values)\n",
    "\n",
    "X_test.head()\n",
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        int64\n",
       "Sex          object\n",
       "Age         float64\n",
       "SibSp         int64\n",
       "Parch         int64\n",
       "Fare        float64\n",
       "Cabin        object\n",
       "Embarked     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert input data into serialized Example strings.\n",
    "def makeExamplesFromRaw(inputs):\n",
    "    examples = []\n",
    "    for index, row in inputs.iterrows():\n",
    "        feature = {}\n",
    "        for col, value in row.iteritems():\n",
    "            feature[col] = tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "        example = tf.train.Example(\n",
    "            features=tf.train.Features(\n",
    "                feature=feature\n",
    "            )\n",
    "        )\n",
    "        examples.append(example.SerializeToString())\n",
    "    return examples\n",
    "\n",
    "examples = makeExamplesFromRaw(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = predict_fn({'inputs': examples})\n",
    "predictions  # looks like a survivor\n",
    "y_preds = [int(x[1].round(0)) for x in predictions['scores']]\n",
    "np.sum(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengerids = inputs['PassengerId'].values\n",
    "passengerids\n",
    "mysub = pd.DataFrame({'PassengerId': passengerids, 'Survived': y_preds})\n",
    "mysub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mysub.to_csv('Submissions/190521/first_cleanB.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/gender_submission.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('Submissions/190521/first_cleanB.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
